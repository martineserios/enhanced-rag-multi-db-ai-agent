{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c19a5af",
   "metadata": {},
   "source": [
    "# GLP-1 Treatment AI Agent Demo\n",
    "This is a Jupyter notebook version of the GLABITAI GLP-1 Treatment AI Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc551a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph Setup\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List, Dict, Any, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "# Remove: from pydantic_ai import Agent, Tool\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq  # or your preferred LLM\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import redis\n",
    "import chromadb\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.graph import Graph\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from bson.errors import InvalidId\n",
    "from bson.objectid import ObjectId\n",
    "from typing import Any, List, TypedDict, Annotated, Optional\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration # To maintain the original return type\n",
    "from langgraph.graph import StateGraph, END\n",
    "import operator # For Annotated with operator.add\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Environment configuration\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\", \"mongodb://glabitai:dev_password@mongodb:27017/\")\n",
    "MONGODB_DB = os.getenv(\"MONGODB_DB\", \"glabitai_glp1_clinical\")\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://redis:6379/0\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"no-key-found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bbb3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Models\n",
    "class PatientData(TypedDict):\n",
    "    patient_id: str\n",
    "    name: str\n",
    "    age: int\n",
    "    weight_kg: float\n",
    "    treatment_start_date: str\n",
    "    current_dosage_mg: float\n",
    "    notes: str\n",
    "    _id: Optional[str] = None\n",
    "    last_visit: Optional[str] = None\n",
    "    next_visit: Optional[str] = None\n",
    "    side_effects: Optional[List[str]] = None\n",
    "\n",
    "class AnalysisResult(TypedDict):\n",
    "    assessment: str\n",
    "    concerns: List[str]\n",
    "    recommendations: List[str]\n",
    "    confidence_score: float\n",
    "    generated_at: str\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    patient_id: str\n",
    "    patient_data: Optional[PatientData]\n",
    "    analysis: Optional[AnalysisResult]\n",
    "    current_step: str\n",
    "    error: Optional[str]\n",
    "    next_steps: List[str]\n",
    "    timestamp: str\n",
    "    processing_time: Optional[float] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedb801",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/root-validator-pre-skip",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGLPAgent\u001b[39;00m:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/__init__.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mabsolute()\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m _f:\n\u001b[1;32m      6\u001b[0m     __version__ \u001b[38;5;241m=\u001b[39m _f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MRKLChain, ReActChain, SelfAskWithSearchChain\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ConversationChain,\n\u001b[1;32m     11\u001b[0m     LLMChain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     VectorDBQAWithSourcesChain,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocstore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryDocstore, Wikipedia\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/agents/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Routing chains.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_agent\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrkl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MRKLChain, ZeroShotAgent\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/agents/agent.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chain\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChainedInput, get_color_mapping\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Chains are easily reusable components which can be linked together.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationChain\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_math\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMMathChain\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/conversation/base.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Extra, Field, root_validator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PROMPT\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/conversation/memory.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, root_validator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SUMMARY_PROMPT\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/conversation/prompt.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[1;32m      4\u001b[0m _DEFAULT_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mCurrent conversation:\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;132;01m{history}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mHuman: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mAI:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m PROMPT \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m     11\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m], template\u001b[38;5;241m=\u001b[39m_DEFAULT_TEMPLATE\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/prompts/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Prompt template classes.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasePromptTemplate\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfew_shot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FewShotPromptTemplate\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_prompt\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/prompts/base.py:35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid prompt schema.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBasePromptTemplate\u001b[39;00m(BaseModel, ABC):\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Base prompt should expose the format method, returning a prompt.\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     input_variables: List[\u001b[38;5;28mstr\u001b[39m]\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/langchain/prompts/base.py:41\u001b[0m, in \u001b[0;36mBasePromptTemplate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m input_variables: List[\u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A list of the names of the variables the prompt template expects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_variable_names\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate variable names do not restricted names.\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/pydantic/deprecated/class_validators.py:240\u001b[0m, in \u001b[0;36mroot_validator\u001b[0;34m(pre, skip_on_failure, allow_reuse, *__args)\u001b[0m\n\u001b[1;32m    238\u001b[0m mode: Literal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m skip_on_failure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    243\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot-validator-pre-skip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    246\u001b[0m wrap \u001b[38;5;241m=\u001b[39m partial(_decorators_v1\u001b[38;5;241m.\u001b[39mmake_v1_generic_root_validator, pre\u001b[38;5;241m=\u001b[39mpre)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdec\u001b[39m(f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mclassmethod\u001b[39m[Any, Any, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstaticmethod\u001b[39m[Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "\u001b[0;31mPydanticUserError\u001b[0m: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/root-validator-pre-skip"
     ]
    }
   ],
   "source": [
    "\n",
    "class GLPAgent:\n",
    "    def __init__(self, model_name=\"mixtral-8x7b-32768\"):\n",
    "        \"\"\"Initialize the GLP-1 Treatment Analysis Agent with Groq and LangGraph.\"\"\"\n",
    "        self.llm = ChatGroq(\n",
    "            model_name=model_name,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "\n",
    "        # System prompt to guide the AI's responses\n",
    "        self.system_prompt = \"\"\"You are a helpful AI assistant specialized in GLP-1 treatment analysis.\n",
    "        You analyze patient data and provide insights about their GLP-1 treatment progress.\n",
    "        Be concise, professional, and focus on actionable insights.\"\"\"\n",
    "\n",
    "\n",
    "    async def run(self, prompt: str) -> Any: # Retaining Any, but it implies ChatGeneration\n",
    "        \"\"\"Run the agent with the given prompt using the LangGraph application.\"\"\"\n",
    "        try:\n",
    "            # Prepare the initial list of messages for the graph's state\n",
    "            initial_messages: List[BaseMessage] = [\n",
    "                SystemMessage(content=self.system_prompt),\n",
    "                HumanMessage(content=prompt)\n",
    "            ]\n",
    "            \n",
    "            # Define the initial state to pass to the graph.\n",
    "            # LangGraph will create 'final_chat_generation' as None if not provided and Optional.\n",
    "            initial_graph_state = {\"messages\": initial_messages}\n",
    "            \n",
    "            # Invoke the LangGraph app asynchronously\n",
    "            # The app will execute the graph starting from the entry point\n",
    "            final_state: AgentState = await self.app.ainvoke(initial_graph_state)\n",
    "            \n",
    "            # Extract the ChatGeneration object from the final state of the graph\n",
    "            # This was set by the _run_llm_and_get_generation node\n",
    "            if final_state and \"final_chat_generation\" in final_state and final_state[\"final_chat_generation\"] is not None:\n",
    "                return final_state[\"final_chat_generation\"]\n",
    "            else:\n",
    "                # Fallback if something unexpected happened, though unlikely in this simple graph\n",
    "                # Try to return the last message if available, or an error string\n",
    "                last_message = final_state[\"messages\"][-1] if final_state.get(\"messages\") else None\n",
    "                if isinstance(last_message, AIMessage):\n",
    "                    # This is not a ChatGeneration object, but it's better than nothing\n",
    "                    # For strictness, one might raise an error here.\n",
    "                    # However, returning the AIMessage's content or object might be a graceful fallback.\n",
    "                    # For now, signaling an issue in retrieving the ChatGeneration.\n",
    "                    return f\"Error: final_chat_generation not found in state. Last AI message: {last_message.content if last_message else 'None'}\"\n",
    "                return \"Error: Could not retrieve ChatGeneration from agent's final state.\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            # import traceback\n",
    "            # print(f\"Detailed error in GLPAgent.run: {traceback.format_exc()}\") # For debugging\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "\n",
    "# Define the state schema\n",
    "class PatientState(TypedDict):\n",
    "    # Input\n",
    "    patient_id: str\n",
    "    \n",
    "    # Data\n",
    "    patient: Optional[Dict[str, Any]] = None\n",
    "    analysis: Optional[Dict[str, Any]] = None\n",
    "    \n",
    "    # Processing\n",
    "    current_step: str\n",
    "    error: Optional[str] = None\n",
    "    timestamp: str\n",
    "    processing_time: Optional[float] = None\n",
    "\n",
    "# Tooling Setup\n",
    "class MongoTool:\n",
    "    def __init__(self, mongo_uri: str, db_name: str):\n",
    "        from pymongo import MongoClient\n",
    "        self.client = MongoClient(mongo_uri)\n",
    "        self.db = self.client[db_name]\n",
    "\n",
    "    def query(self, patient_id: str) -> Optional[Dict]:\n",
    "        \"\"\"Fetch patient data from MongoDB with error handling.\"\"\"\n",
    "        try:\n",
    "            result = self.db.patients.find_one({\"patient_id\": patient_id})\n",
    "            if result and '_id' in result:\n",
    "                result['_id'] = str(result['_id'])\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"MongoDB query failed: {str(e)}\")\n",
    "\n",
    "class RedisTool:\n",
    "    def __init__(self, url: str):\n",
    "        import redis\n",
    "        try:\n",
    "            self.client = redis.Redis.from_url(url, decode_responses=True)\n",
    "            self.client.ping()  # Test connection\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Redis connection failed: {str(e)}\")\n",
    "\n",
    "    def cache_analysis(self, key: str, value: Dict[str, Any], ttl: int = 86400) -> bool:\n",
    "        \"\"\"Cache analysis with TTL (default 24 hours).\"\"\"\n",
    "        try:\n",
    "            return self.client.setex(f\"analysis:{key}\", ttl, json.dumps(value))\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Redis cache update failed: {str(e)}\")\n",
    "\n",
    "    def get_cached_analysis(self, key: str) -> Optional[Dict]:\n",
    "        \"\"\"Retrieve cached analysis if exists and not expired.\"\"\"\n",
    "        try:\n",
    "            result = self.client.get(f\"analysis:{key}\")\n",
    "            return json.loads(result) if result else None\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Redis cache retrieval failed: {str(e)}\")\n",
    "\n",
    "class ChromaTool:\n",
    "    def __init__(self, collection_name: str = \"patients\"):\n",
    "        import chromadb\n",
    "        try:\n",
    "            self.client = chromadb.Client()\n",
    "            self.collection = self.client.get_or_create_collection(name=collection_name)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"ChromaDB initialization failed: {str(e)}\")\n",
    "\n",
    "    def upsert(self, document: Dict, metadata: Optional[Dict] = None) -> None:\n",
    "        \"\"\"Upsert document with metadata.\"\"\"\n",
    "        try:\n",
    "            doc_id = document.get(\"patient_id\", str(hash(json.dumps(document, sort_keys=True))))\n",
    "            self.collection.upsert(\n",
    "                ids=[doc_id],\n",
    "                documents=[json.dumps(document)],\n",
    "                metadatas=[metadata] if metadata else None\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"ChromaDB upsert failed: {str(e)}\")\n",
    "\n",
    "# Initialize tools with error handling\n",
    "try:\n",
    "    mongo_tool = MongoTool(MONGODB_URI, MONGODB_DB)\n",
    "    redis_tool = RedisTool(REDIS_URL)\n",
    "    chroma_tool = ChromaTool()\n",
    "except Exception as e:\n",
    "    print(f\"Tool initialization error: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "\n",
    "# Define state transitions\n",
    "async def fetch_patient(state: PatientState) -> PatientState:\n",
    "    \"\"\"Fetch patient data from MongoDB using _id.\"\"\"\n",
    "    state[\"current_step\"] = \"fetching_patient\"\n",
    "    try:\n",
    "        # Convert string ID to ObjectId for the query\n",
    "        patient_id = state[\"patient_id\"]\n",
    "        \n",
    "        # Query using _id field\n",
    "        patient = mongo_tool.db.patients.find_one({\"_id\": ObjectId(patient_id)})\n",
    "        \n",
    "        if not patient:\n",
    "            raise ValueError(f\"Patient with _id {patient_id} not found\")\n",
    "            \n",
    "        # Convert ObjectId to string for JSON serialization\n",
    "        if '_id' in patient:\n",
    "            patient['_id'] = str(patient['_id'])\n",
    "            \n",
    "        return {**state, \"patient\": patient}\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error fetching patient: {str(e)}\"\n",
    "        print(error_msg)  # Debug log\n",
    "        return {**state, \"error\": error_msg}\n",
    "\n",
    "        \n",
    "async def analyze_with_agent(state: PatientState) -> PatientState:\n",
    "    \"\"\"Analyze patient data using AI agent.\"\"\"\n",
    "    if not state.get(\"patient\"):\n",
    "        return {**state, \"error\": \"No patient data available for analysis\"}\n",
    "    \n",
    "    state[\"current_step\"] = \"analyzing\"\n",
    "    try:\n",
    "        agent = GLPAgent()\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this patient's GLP-1 treatment progress:\n",
    "\n",
    "        Patient Data:\n",
    "        {json.dumps(state[\"patient\"], indent=2, default=str)}\n",
    "\n",
    "        Provide structured analysis with:\n",
    "        1. Treatment progress assessment\n",
    "        2. Any concerns or considerations\n",
    "        3. Recommended next steps\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await agent.run(prompt)\n",
    "        analysis = {\n",
    "            \"content\": response.content,\n",
    "            \"generated_at\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        return {**state, \"analysis\": analysis}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {**state, \"error\": f\"Analysis failed: {str(e)}\"}\n",
    "\n",
    "\n",
    "        \n",
    "async def cache_and_store(state: PatientState) -> PatientState:\n",
    "    \"\"\"Cache analysis and store patient data.\"\"\"\n",
    "    print(state)\n",
    "    if not state.get(\"patient\") or not state.get(\"analysis\"):\n",
    "        \n",
    "        return {**state, \"error\": \"Incomplete data for storage\"}\n",
    "    \n",
    "    state[\"current_step\"] = \"storing_results\"\n",
    "    try:\n",
    "        patient_id = state[\"patient\"][\"patient_id\"]\n",
    "        \n",
    "        # Cache analysis in Redis\n",
    "        redis_tool.cache_analysis(patient_id, state[\"analysis\"])\n",
    "        \n",
    "        # Store in ChromaDB\n",
    "        chroma_tool.upsert(\n",
    "            document=state[\"patient\"],\n",
    "            metadata={\n",
    "                \"last_analyzed\": datetime.utcnow().isoformat(),\n",
    "                \"analysis_timestamp\": state[\"analysis\"][\"generated_at\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {**state, \"error\": f\"Storage failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d3cab-036b-4f69-948d-33a2258a7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure the graph\n",
    "def create_patient_analysis_workflow() -> Graph:\n",
    "    \"\"\"Create and configure the patient analysis workflow.\"\"\"\n",
    "    workflow = StateGraph(PatientState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"fetch_patient\", fetch_patient)\n",
    "    workflow.add_node(\"analyze\", analyze_with_agent)\n",
    "    workflow.add_node(\"store_results\", cache_and_store)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"fetch_patient\")\n",
    "    workflow.add_edge(\"fetch_patient\", \"analyze\")\n",
    "    workflow.add_edge(\"analyze\", \"store_results\")\n",
    "    workflow.add_edge(\"store_results\", END)\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78285f-a49d-444e-abd3-2d828782bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent Workflow\n",
    "from IPython.display import Image, display\n",
    "\n",
    "workflow = create_patient_analysis_workflow()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a01af-390e-4f53-ab3f-72a2c8b490a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def create_initial_state(patient_id: str) -> PatientState:\n",
    "    \"\"\"Create initial state with timestamp and default values.\"\"\"\n",
    "    return {\n",
    "        \"patient_id\": patient_id,\n",
    "        \"patient\": None,\n",
    "        \"analysis\": None,\n",
    "        \"current_step\": \"initialized\",\n",
    "        \"timestamp\": datetime.utcnow().isoformat()\n",
    "    }\n",
    "\n",
    "\n",
    "async def analyze_patient(patient_id: str, workflow) -> Dict[str, Any]:\n",
    "    \"\"\"Run the analysis pipeline for a patient.\"\"\"\n",
    "    initial_state = create_initial_state(patient_id)\n",
    "    \n",
    "    try:\n",
    "        result = await workflow.ainvoke(initial_state)\n",
    "        if result.get(\"error\"):\n",
    "            print(f\"Analysis completed with errors: {result['error']}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"patient_id\": patient_id,\n",
    "            \"error\": f\"Workflow execution failed: {str(e)}\",\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "\n",
    "# Example usage in notebook\n",
    "result = await analyze_patient(\"683613805f2537d439303bbf\", workflow)\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "else:\n",
    "    print(f\"Analysis completed: {json.dumps(result['analysis'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72981563-b8f4-4298-b7ee-71b437b30f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
